---
title: "AACR Feedback Report"
output: 
  html_document:
    toc: true
    css: custom.css
---

<META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">


```{r,echo=FALSE,results='hide',warning=FALSE,message=FALSE,cache=FALSE}
library(knitr)
library(igraph)
library(stringr)
library(RColorBrewer)
library(tables)
library(pander)
library(plotly)

opts_chunk$set(cache=FALSE,echo=FALSE)
```

<br>

# Student Response Scoring

## Rubric Level Distribution and Description

**QUESTION: `r params$questionText`**

For this question, your students fall into `r length(params$groupLevels)` rubric bins. Students with similar ideas fall into the same rubric bin. The `r length(params$groupLevels)` rubric bins and the number of student responses in each rubric bin are shown in the figure below. The rubric bins are not mutually exclusive, so any individual response may appear in multiple bins.

```{r,echo=FALSE,fig.height=4,message=FALSE,warning=FALSE}

makeBinaryScoringPlot(params)

```

<br>

```{r,echo=FALSE,comment=NA,results='asis',cache=FALSE}
print(kable(params$questionRubric[,c("Rubric Level","Description")],caption="Item Rubric"))

```

## Scoring by Rubric Bin and Associated Probability

```{r,echo=FALSE,comment=NA,results='asis',cache=FALSE}

datatable(params$responseByGroup,rownames=FALSE,options=list(pageLength=3))
``` 

<br>

## Rubric Bin Associations
### Association Web Diagram
The circular nodes in this plot correspond with the item rubric bins. The edges (lines) connecting the nodes correspond to co-occurence rates bewtween the rubric bins in the scored sample. In this diagram both nodes and edges are scaled in size and color to represent the range of rubric bin and co-occurence frequencies as shown in the figure keys.

```{r,echo=FALSE,message=FALSE,warning=FALSE,results='asis',fig.height=3.5}
makeCooccurWD(params,values,inset=-0.07)
```

### Association Frequencies

The co-occurence freqencies displayed in the figures below describe the fraction of student responses which have been score for the rubric bin appearing in the title that also are scored for the rubric bins listed on the vertical axis.

```{r,echo=FALSE,message=FALSE,warning=FALSE,results='asis',fig.height=3.5}
for(gLevel in params$wdMenuList){
        # print(makeCooccurFreqPlot(values,params,gLevel,static=FALSE))
        print(makeCooccurFreqPlot(values,params,gLevel,static=TRUE))
        
        cat("\n\n")

}
```


### Association Odds Ratio
The figures in the follow section display the probabilities of co-occurences between rubric bins. Each figure considers all the responses that have been scored for a given rubric bin and displays the proabilities that those bins have also been coded for the other rubric bins, relative to the occurance of those bins in the complete response set. The metric used here is refered to as the conditional probability. A conditional probability of 0.5 indicates that the rubric level responses repressented by the labled bar is half as likely to appear in responses which also are scored for the co-occurant rubric level as they do in the full response set. For a value of 1.3 the relevantly score responses occur 30 percent likely to appear with the co-occurant rubric level than is a given response drawn from the full response set.

```{r, include=FALSE,echo=FALSE,eval=TRUE}
out = NULL
for (gLevel in params$wdMenuList) {
        env <- new.env()
  out = c(out, knit_child('condFreqPlot.Rmd',envir=env))
}
```

`r paste(out, collapse='\n')`

$$ Conditional Frequency = \frac{\frac{N(Rubric Level|Co-occurant Rubric Level)}{N(Co-occurant Rubric Level)}}{\frac{N(Rubric Level)}{N}}$$


<br>

# Analysis of Term Usage
## Most Important Terms

The n-gram overabundance provides a measure of the relative prevalence of a n-gram in a the set of resposes texts in a rubric bin. Specifically, overabundance measures the frequency of a n-gram in the response texts of a given rubric bin with respect to the full set of responses. An overabundance of 0.5 indicates that the n-gram appears 50% more frequently in the responses of the specified rubric bin that it does in the overall set of responses. A value of -0.25 means that the n-gram occurs 25% less often in the relevant rubric bin and than in the overall set.  

```{r,echo=FALSE,comment=NA,results='asis',cache=FALSE}
datatable(params$oAbDF,rownames=FALSE,options=list(pageLength=10,searching=FALSE))
``` 

$$ Overabundance = \frac{\frac{N(term|score)}{N(score)}-\frac{N(term)}{N}}{\frac{N(term)}{N}}$$

<br>

## Web Diagrams of Important Terms

The web diagrams shown here display the frequency and co-occurence rates of the most overabundant n-grams in each rubric bin. The circular node symbols display the frequency of n-gram occurence as a fraction of responses scored in the rubric bin which contain a given n-gram. The lines connecting the nodes indicate the frequency for which the two connected n-grams appear together as a fraction of responses in the rubric bin. Highly correlated groups or clusters of n-grams represent common phrases, sentances, and concepts appearing in student responses.

```{r,echo=FALSE,message=FALSE,warning=FALSE}
for(gLevel in params$wdMenuList){
        makeWebDiagram(params,values,gLevel,inset=-0.07)
}
```

<br>

## Term Usage and Association Maps

The following correlation maps show the most common n-grams for each rubric bin and there mutual correlations represented as an network graph. Each n-gram is displayed as a node, with highly correlated n-grams being connected with lines. The thicker the line connecting two n-grams the stronger they are correlated in the rubric bins response set. Highly correlated groups or clusters of n-grams represent common phrases, sentances, and concepts appearing in student responses.

```{r,echo=FALSE,message=FALSE,warning=FALSE}
probThreshold <- 0
# corThreshold <- 0.3
minNumTerms <- 5
maxNumTerms <- 25


for(gLevel in params$wdMenuList){
        rubricLevelIndex <- values$predict[[as.numeric(gLevel)]]$rubricLevel==1 &
                values$predict[[as.numeric(gLevel)]]$probability>probThreshold
        dtmTmp <- values$docTermMat[rubricLevelIndex,]
        minFreq <- ifelse(length(findFreqTerms(dtmTmp,lowfreq = 15))>minNumTerms,15,findMinFreq(dtmTmp)) # find minimum minimum frequency
        minFreq <- ifelse(length(findFreqTerms(dtmTmp,lowfreq = minFreq))>maxNumTerms,findMinFreq(dtmTmp,maxNumTerms),minFreq) #find maximum minimum frequency
        corThreshold <- params$mapControlLimits[[as.numeric(gLevel)]][4]
        makeTermMap(dtmTmp,minFreq,corThreshold)
        title(names(params$wdMenuList[gLevel]))
        
        cat("\n\n")
}
```

<br>

# Reference: Scoring Model Performance
## Scoring Model Cross Validation
**Please Note:** The data in the following section refers to the cross validation of the scoring model training set. This data does not refer to the data uploaded and scored in the production of this Instructor Feedback Report. It is presented to give the background information on the performance of the `r params$questionText` item scoring model.


```{r,echo=FALSE,results='hide',warning=FALSE,message=FALSE,cache=FALSE}
kappaOut <- as.numeric(sapply(seq(length(values$cvOut)),function(x) values$cvOut[[x]][["overall"]]["Kappa"]))
matOut <- as.numeric(sapply(seq(length(values$cvOut)),function(x) sum(values$cvOut[[x]][["table"]][2,])))
matIn <- as.numeric(sapply(seq(length(values$cvOut)),function(x) sum(values$cvOut[[x]][["table"]][,2])))

```

### Summary
Training set site per fold: N= `r values$trainLength`  
Total number of scored responses: `r values$scoreLength` 

```{r,echo=FALSE}
rubricLevelNames <- params$questionRubric[,"Rubric Level"]
sumTable <- rbind(matIn,matOut,kappaOut)
row.names(sumTable) <- c("Human","Machine","Kappa")
colnames(sumTable) <- values$rubricLevelNames
kable(t(sumTable),caption="Total responses per bin ",digits=3)
```

```{r,echo=FALSE,comment=NA,message=FALSE,results='asis'}
i<-1
for(cvTmp in values$cvOut){
        cat("\n\\pagebreak\n\n")
        cat(paste("## Rubric Bin:",rubricLevelNames[i],"\n"))
        cat("### Confusion Matrix")
        cat("\n\n")
        html(as.tabular(addmargins(cvTmp$table)))
        # html(as.tabular(cvTmp$table))
        # pander(as.tabular(cvTmp$table))
        
        cat("\n\n")

        cat("### Overall Statistics")
        cat("\n")
        dfOut <- data.frame(
                Kappa=round(cvTmp$overall["Kappa"],3),
                Accuracy=round(cvTmp$overall["Accuracy"],3),
                "Accuracy 95% CI"=paste(round(cvTmp$overall["AccuracyLower"],digits=3),"-",round(cvTmp$overall["AccuracyUpper"],digits=3)),
                "No Information Rate"=round(cvTmp$overall["AccuracyNull"],3),
                "P-Value [Acc > NIR]"=signif(cvTmp$overall["AccuracyPValue"],3),
                "McNemar's Test P-Value"=signif(cvTmp$overall["McnemarPValue"],3),check.names = FALSE,row.names = NULL
        )
        print(kable(t(dfOut),digits=3))
        cat("\n")
        
        cat("### By Rubric Bin")
        cat("\n")
        print(kable(cvTmp$byClass,digits=3))
        cat("\n\n")
        i<- i+1
}
        
        
```



